@article{kernelized-stein-discrepancy,
abstract = {We derive a new discrepancy statistic for measuring differences between two probability distributions based on combining Stein's identity with the reproducing kernel Hilbert space theory. We apply our result to test how well a probabilistic model fits a set of observations, and derive a new class of powerful goodness-of-fit tests that are widely applicable for complex and high dimensional distributions, even for those with computationally intractable normalization constants. Both theoretical and empirical properties of our methods are studied thoroughly.},
archivePrefix = {arXiv},
arxivId = {1602.03253},
author = {Liu, Qiang and Lee, Jason D. and Jordan, Michael I.},
eprint = {1602.03253},
file = {:Users/jarotter/Documents/ITAM/tesis/refs/svgd/kernelized-stein-discrepancy.pdf:pdf},
number = {1},
title = {{A Kernelized Stein Discrepancy for Goodness-of-fit Tests and Model Evaluation}},
url = {http://arxiv.org/abs/1602.03253},
year = {2016}
}

@article{svgd,
abstract = {We propose a general purpose variational inference algorithm that forms a natural counterpart of gradient descent for optimization. Our method iteratively transports a set of particles to match the target distribution, by applying a form of functional gradient descent that minimizes the KL divergence. Empirical studies are performed on various real world models and datasets, on which our method is competitive with existing state-of-the-art methods. The derivation of our method is based on a new theoretical result that connects the derivative of KL divergence under smooth transforms with Stein's identity and a recently proposed kernelized Stein discrepancy, which is of independent interest.},
archivePrefix = {arXiv},
arxivId = {1608.04471},
author = {Liu, Qiang and Wang, Dilin},
eprint = {1608.04471},
file = {:Users/jarotter/Documents/ITAM/tesis/refs/svgd/svgd.pdf:pdf},
issn = {10495258},
pages = {4--7},
pmid = {18792489},
title = {{Stein Variational Gradient Descent: A General Purpose Bayesian Inference Algorithm}},
url = {http://arxiv.org/abs/1608.04471},
year = {2016}
}

@article{svgd-gradient-flow,
abstract = {Stein variational gradient descent (SVGD) is a deterministic sampling algorithm that iteratively transports a set of particles to approximate given distributions, based on a gradient-based update that guarantees to optimally decrease the KL divergence within a function space. This paper develops the first theoretical analysis on SVGD. We establish that the empirical measures of the SVGD samples weakly converge to the target distribution, and show that the asymptotic behavior of SVGD is characterized by a nonlinear Fokker-Planck equation known as Vlasov equation in physics. We develop a geometric perspective that views SVGD as a gradient flow of the KL divergence functional under a new metric structure on the space of distributions induced by Stein operator.},
author = {Liu, Qiang},
file = {:Users/jarotter/Documents/ITAM/tesis/refs/svgd/svgd-gradient-flow.pdf:pdf},
number = {Nips},
title = {{Stein variational gradient descent as gradient flow}},
url = {http://papers.nips.cc/paper/6904-stein-variational-gradient-descent-as-gradient-flow},
year = {2017}
}

@article{svgd-moment-matching,
abstract = {Stein variational gradient descent (SVGD) is a non-parametric inference algorithm that evolves a set of particles to fit a given distribution of interest. We analyze the non-asymptotic properties of SVGD, showing that there exists a set of functions, which we call the Stein matching set, whose expectations are exactly estimated by any set of particles that satisfies the fixed point equation of SVGD. This set is the image of Stein operator applied on the feature maps of the positive definite kernel used in SVGD. Our results provide a theoretical framework for analyzing the properties of SVGD with different kernels, shedding insight into optimal kernel choice. In particular, we show that SVGD with linear kernels yields exact estimation of means and variances on Gaussian distributions, while random Fourier features enable probabilistic bounds for distributional approximation. Our results offer a refreshing view of the classical inference problem as fitting Stein's identity or solving the Stein equation, which may motivate more efficient algorithms.},
archivePrefix = {arXiv},
arxivId = {1810.11693},
author = {Liu, Qiang and Wang, Dilin},
doi = {arXiv:1810.11693v1},
eprint = {1810.11693},
file = {:Users/jarotter/Documents/ITAM/tesis/refs/svgd/svgd-moment-matching.pdf:pdf},
issn = {10495258},
pmid = {18792489},
title = {{Stein Variational Gradient Descent as Moment Matching}},
url = {http://arxiv.org/abs/1810.11693},
year = {2018}
}

@article{measuring-quality,
abstract = {Approximate Markov chain Monte Carlo (MCMC) offers the promise of more rapid sampling at the cost of more biased inference. Since standard MCMC diagnostics fail to detect these biases, researchers have developed computable Stein discrepancy measures that provably determine the convergence of a sample to its target distribution. This approach was recently combined with the theory of reproducing kernels to define a closed-form kernel Stein discrepancy (KSD) computable by summing kernel evaluations across pairs of sample points. We develop a theory of weak convergence for KSDs based on Stein's method, demonstrate that commonly used KSDs fail to detect non-convergence even for Gaussian targets, and show that kernels with slowly decaying tails provably determine convergence for a large class of target distributions. The resulting convergence-determining KSDs are suitable for comparing biased, exact, and deterministic sample sequences and simpler to compute and parallelize than alternative Stein discrepancies. We use our tools to compare biased samplers, select sampler hyperparameters, and improve upon existing KSD approaches to one-sample hypothesis testing and sample quality improvement.},
archivePrefix = {arXiv},
arxivId = {1703.01717},
author = {Gorham, Jackson and Mackey, Lester},
doi = {10.1016/j.bbr.2008.10.038},
eprint = {1703.01717},
file = {:Users/jarotter/Documents/ITAM/tesis/refs/svgd/deeper/measuring-sample-quality.pdf:pdf},
isbn = {0022-0515},
issn = {1872-7549},
pmid = {19041347},
title = {{Measuring Sample Quality with Kernels}},
url = {http://arxiv.org/abs/1703.01717},
year = {2017}
}

@article{vi,
abstract = {One of the core problems of modern statistics is to approximate difficult-to-compute probability densities. This problem is especially important in Bayesian statistics, which frames all inference about unknown quantities as a calculation involving the posterior density. In this paper, we review variational inference (VI), a method from machine learning that approximates probability densities through optimization. VI has been used in many applications and tends to be faster than classical methods, such as Markov chain Monte Carlo sampling. The idea behind VI is to first posit a family of densities and then to find the member of that family which is close to the target. Closeness is measured by Kullback-Leibler divergence. We review the ideas behind mean-field variational inference, discuss the special case of VI applied to exponential family models, present a full example with a Bayesian mixture of Gaussians, and derive a variant that uses stochastic optimization to scale up to massive data. We discuss modern research in VI and highlight important open problems. VI is powerful, but it is not yet well understood. Our hope in writing this paper is to catalyze statistical research on this class of algorithms.},
archivePrefix = {arXiv},
arxivId = {arXiv:1601.00670v9},
author = {Blei, David M. and Kucukelbir, Alp and McAuliffe, Jon D.},
doi = {10.1080/01621459.2017.1285773},
eprint = {arXiv:1601.00670v9},
file = {:Users/jarotter/Documents/ITAM/tesis/refs/svgd/deeper/inferencia-variacional.pdf:pdf},
isbn = {1601.00670},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Algorithms,Computationally intensive methods,Statistical computing},
number = {518},
pages = {859--877},
pmid = {303902},
title = {{Variational Inference: A Review for Statisticians}},
volume = {112},
year = {2017}
}

@article{random-features-kernel,
author = {Rahimi, Ali and Recht, Ben},
doi = {10.1007/s12204-009-0467-7},
file = {:Users/jarotter/Documents/ITAM/tesis/refs/svgd/deeper/random-features-kernel.pdf:pdf},
isbn = {160560352X},
issn = {10071172},
pmid = {4519940},
title = {{Random Features for Large-Scale Kernel Machines}}
}

@article{advi,
abstract = {Probabilistic modeling is iterative. A scientist posits a simple model, fits it to her data, refines it according to her analysis, and repeats. However, fitting complex models to large data is a bottleneck in this process. Deriving algorithms for new models can be both mathematically and computationally challenging, which makes it difficult to efficiently cycle through the steps. To this end, we develop automatic differentiation variational inference (ADVI). Using our method, the scientist only provides a probabilistic model and a dataset, nothing else. ADVI automatically derives an efficient variational inference algorithm, freeing the scientist to refine and explore many models. ADVI supports a broad class of models-no conjugacy assumptions are required. We study ADVI across ten different models and apply it to a dataset with millions of observations. ADVI is integrated into Stan, a probabilistic programming system; it is available for immediate use.},
archivePrefix = {arXiv},
arxivId = {1603.00788},
author = {Kucukelbir, Alp and Tran, Dustin and Ranganath, Rajesh and Gelman, Andrew and Blei, David M.},
doi = {10.3847/0004-637X/819/1/50},
eprint = {1603.00788},
file = {:Users/jarotter/Documents/ITAM/8 - Oto{\~{n}}o 2018/proyecto{\_}simulacion/docs/1603.00788.pdf:pdf},
isbn = {1603.00788},
issn = {15337928},
pages = {1--38},
title = {{Automatic Differentiation Variational Inference}},
url = {http://arxiv.org/abs/1603.00788},
year = {2016}
}

@book{rkhs-book,
author = {Berlinet, Alain and Thomas-Agnan, Christine},
doi = {10.1142/9789812835635_0014},
file = {:Users/jarotter/Documents/ITAM/tesis/refs/rkhs/Alain Berlinet, Christine Thomas-Agnan - Reproducing Kernel Hilbert Spaces in Probability and Statistics (2004, Springer).pdf:pdf},
isbn = {9781461347927},
pages = {153--162},
publisher = {Springer Science + Business Media},
title = {{Reproducing Kernels in Probability and Statistics}},
year = {2009}
}


@article{bayesian-gradient-flow,
abstract = {The Bayesian update can be viewed as a variational problem by characterizing the posterior as the minimizer of a functional. The variational viewpoint is far from new and is at the heart of popular methods for posterior approximation. However, some of its consequences seem largely unexplored. We focus on the following one: defining the posterior as the minimizer of a functional gives a natural path towards the posterior by moving in the direction of steepest descent of the functional. This idea is made precise through the theory of gradient flows, allowing to bring new tools to the study of Bayesian models and algorithms. Since the posterior may be characterized as the minimizer of different functionals, several variational formulations may be considered. We study three of them and their three associated gradient flows. We show that, in all cases, the rate of convergence of the flows to the posterior can be bounded by the geodesic convexity of the functional to be minimized. Each gradient flow naturally suggests a nonlinear diffusion with the posterior as invariant distribution. These diffusions may be discretized to build proposals for Markov chain Monte Carlo (MCMC) algorithms. By construction, the diffusions are guaranteed to satisfy a certain optimality condition, and rates of convergence are given by the convexity of the functionals. We use this observation to propose a criterion for the choice of metric in Riemannian MCMC methods.},
archivePrefix = {arXiv},
arxivId = {1705.07382},
author = {Trillos, Nicolas Garcia and Sanz-Alonso, Daniel},
eprint = {1705.07382},
file = {:Users/jarotter/Documents/ITAM/tesis/refs/povi/bayesian-gradient-flow.pdf:pdf},
keywords = {convexity,gradient flows,riemannian mcmc,wasserstein space},
number = {0},
pages = {1--30},
title = {{The Bayesian update: variational formulations and gradient flows}},
url = {http://arxiv.org/abs/1705.07382},
year = {2017}
}

@article{advances-vi,
abstract = {Many modern unsupervised or semi-supervised machine learning algorithms rely on Bayesian probabilistic models. These models are usually intractable and thus require approximate inference. Variational inference (VI) lets us approximate a high-dimensional Bayesian posterior with a simpler variational distribution by solving an optimization problem. This approach has been successfully used in various models and large-scale applications. In this review, we give an overview of recent trends in variational inference. We first introduce standard mean field variational inference, then review recent advances focusing on the following aspects: (a) scalable VI, which includes stochastic approximations, (b) generic VI, which extends the applicability of VI to a large class of otherwise intractable models, such as non-conjugate models, (c) accurate VI, which includes variational models beyond the mean field approximation or with atypical divergences, and (d) amortized VI, which implements the inference over local latent variables with inference networks. Finally, we provide a summary of promising future research directions.},
archivePrefix = {arXiv},
arxivId = {1711.05597},
author = {Zhang, Cheng and Butepage, Judith and Kjellstrom, Hedvig and Mandt, Stephan},
doi = {10.1109/TPAMI.2018.2889774},
eprint = {1711.05597},
file = {:Users/jarotter/Documents/ITAM/tesis/docs/vi/advances-variational-inference.pdf:pdf},
isbn = {03051838},
issn = {19393539},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Approximate Bayesian Inference,Bayes methods,Computational modeling,Hidden Markov models,Inference Networks,Market research,Optimization,Probabilistic logic,Reparameterization Gradients,Scalable Inference,Stochastic processes,Structured Variational Approximations,Variational Inference},
pages = {1--23},
pmid = {30596568},
title = {{Advances in Variational Inference}},
year = {2018}
}

@book{robert-book,
address = {New York},
author = {Robert, Christian P. and Casella, George},
edition = {Second},
file = {:Users/jarotter/Documents/estadistica/bayesiana/libros/MCSM casella.pdf:pdf},
isbn = {0-387-21239-6},
publisher = {Springer Science + Business Media},
title = {{Monte Carlo Statistical Methods}},
year = {2004}
}
@article{esl,
abstract = {During the past decade there has been an explosion in computation and information technology. With it has come a vast amount of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Hastie},
doi = {10.1007/b94608},
eprint = {arXiv:1011.1669v3},
file = {:Users/jarotter/Documents/Books/ESLII{\_}print10.pdf:pdf},
isbn = {9780387848570},
issn = {03436993},
journal = {The Mathematical Intelligencer},
number = {2},
pages = {83--85},
pmid = {15512507},
title = {{Springer Series in Statistics The Elements of}},
url = {http://www.springerlink.com/index/D7X7KX6772HQ2135.pdf},
volume = {27},
year = {2009}
}

@article{goodfellow,
abstract = {Deep Learning book},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {{Ian Goodfellow, Yoshua Bengio}, Aaron Courville},
doi = {10.1016/B978-0-12-391420-0.09987-X},
eprint = {arXiv:1011.1669v3},
file = {:Users/jarotter/Documents/data/deep{\_}learning/[Goodfellow]{\_}deep{\_}learning.pdf:pdf},
isbn = {3540620583, 9783540620587},
issn = {1432122X},
journal = {MIT Press},
number = {7553},
pages = {785},
pmid = {21728107},
title = {{The Deep Learning Book}},
volume = {521},
year = {2017}
}

@article{betancourt-hmc,
archivePrefix = {arXiv},
arxivId = {arXiv:1701.02434v2},
author = {Betancourt, Michael},
eprint = {arXiv:1701.02434v2},
file = {:Users/jarotter/Documents/estadistica/bayesiana/mcmc/hamiltonian-mcmc.pdf:pdf},
title = {{A Conceptual Introduction to Hamiltonian Monte Carlo}}
}

@article{coresets,
archivePrefix = {arXiv},
arxivId = {arXiv:1710.05053v2},
author = {Campbell, Trevor and Broderick, Tamara},
eprint = {arXiv:1710.05053v2},
file = {:Users/jarotter/Documents/estadistica/bayesiana/coresets/coresets.pdf:pdf},
pages = {1--36},
title = {{Automated scalable bayesian inference via hilbert coresets}},
year = {2013}
}
@article{coresets-greedy,
archivePrefix = {arXiv},
arxivId = {arXiv:1802.01737v2},
author = {Campbell, Trevor and Broderick, Tamara},
eprint = {arXiv:1802.01737v2},
file = {:Users/jarotter/Documents/estadistica/bayesiana/coresets/coreset-geodesic-ascent.pdf:pdf},
title = {{Bayesian Coreset Construction via Greedy Iterative Geodesic Ascent}},
year = {2018}
}

@article{gelman-philosphy,
abstract = {A substantial school in the philosophy of science identifies Bayesian inference with inductive inference and even rationality as such, and seems to be strengthened by the rise and practical success of Bayesian statistics. We argue that the most successful forms of Bayesian statistics do not actually support that particular philosophy but rather accord much better with sophisticated forms of hypothetico-deductivism. We examine the actual role played by prior distributions in Bayesian models, and the crucial aspects of model checking and model revision, which fall outside the scope of Bayesian confirmation theory. We draw on the literature on the consistency of Bayesian updating and also on our experience of applied work in social science. Clarity about these matters should benefit not just philosophy of science, but also statistical practice. At best, the inductivist view has encouraged researchers to fit and compare models without checking them; at worst, theorists have actively discouraged practitioners from performing model checking because it does not fit into their framework.},
archivePrefix = {arXiv},
arxivId = {arXiv:1006.3868v4},
author = {Gelman, Andrew and Shalizi, Cosma Rohilla},
doi = {10.1111/j.2044-8317.2011.02037.x},
eprint = {arXiv:1006.3868v4},
file = {:Users/jarotter/Documents/estadistica/bayesiana/[Gelman] Philosophy and practice.pdf:pdf},
isbn = {0007-1102},
issn = {00071102},
journal = {British Journal of Mathematical and Statistical Psychology},
number = {1},
pages = {8--38},
pmid = {23050946},
title = {{Philosophy and the practice of Bayesian statistics}},
volume = {66},
year = {2013}
}

@book{bernardo,
abstract = {Within metrology the evaluation of measurement uncertainty plays a special and very important role. In the past the generally accepted procedure for establishing the uncertainty was the so-called error analysis . Within this procedure probability is interpreted strictly in the statistical (frequentist) sense. Since the available information needed to infer the measurand almost never consists of only observed statistical data, the inference on the basis of error analysis showed difficulties that in 1993 were overcome by an international recommendation to apply, at least within the various branches of metrology, Bayesian Statistics to measurement data. But the price to pay for the resulting consistent and satisfying evaluation procedure is to change one's view of probability and to accept the consequences. This needs guidance, particularly for those educated in frequency-based statistics. The book Bayesian Theory , first published in hardback in 1994, provides in about 600 pages a very clear, careful and well structured description of the foundations and key theoretical concepts of Bayesian Statistics. Although not written especially for metrologists and their needs to evaluate measurement data, the text to a large extent can be recommended without restriction to this community as an extensive and excellent introduction and guide to the world of Bayesian coherent reasoning. The detailed comparison with non-Bayesian theories, such as the frequentist procedures, is particularly enlightening in understanding the basic Bayesian concepts. In the volume the authors concentrate on the answer to the question of why Bayesian Statistics should be used at all. Only in future volumes will they deal with analytical and numerical techniques to implement Bayesian procedures and the study of methods of analysis for various types of models and problems. The contents of the book go well beyond the problem of statistical inference, which is viewed as a special case of decision theory. The interpretation of probability in Bayesian Statistics as well as the foundations of probability theory and decision theory are presented. Apart from modelling and model comparison the central Bayesian problem of the prior distribution, particularly in case of ignorance, is addressed at length. It is discussed in conjunction with the introduction of information-theoretic concepts. Critical issues are explicitly mentioned and discussed. Numerous examples illustrate the clearly expounded theoretical considerations. There are about 1500 references (only a few later than 1994) including a list of other Bayesian textbooks. A list of abbreviations and symbols used is unfortunately missing. Whereas the authors throughout focus on statistical concepts rather than rigorous mathematics the reader should be prepared for a mathematical presentation on the level of advanced calculus. The book will not be the primary source for an actual evaluation of the uncertainty of measurement given the model of evaluation and incomplete information about random and systematic effects occurring in measurement. But it certainly is an excellent primary source for those who wish to learn about the learning and decision process in a situation of uncertainty. It is this situation the metrologist faces after measurement when having to state what he has learned about the measurand. Wolfgang W{\"{o}}ger},
author = {Bernardo, Jos{\'{e}} M. and Smith, Adrian F.M.},
booktitle = {Bayesian Theory},
doi = {10.1002/9780470316870},
edition = {Third},
file = {:Users/jarotter/Documents/estadistica/bayesiana/libros/bernardo-bayesian-theory.pdf:pdf},
isbn = {9780470316870},
pages = {1--595},
publisher = {Wiley Series in Probability and Statistics},
title = {{Bayesian Theory}},
year = {2000}
}

@article{shannon1948,
author = {Shannon, Claude E.},
file = {:Users/jarotter/Documents/ITAM/tesis/docs/vi/kl/shannon-info-theory.pdf:pdf},
journal = {Bell System Technical Journal},
number = {July, October},
pages = {379--423},
title = {{A Mathematical Theory of Communication}},
volume = {27},
year = {1948}
}

@techreport{powers1956,
address = {Cambrdige, MA},
author = {Powers, Kerns H.},
file = {:Users/jarotter/Documents/ITAM/tesis/docs/vi/kl/unified-theory-information.pdf:pdf},
institution = {Research laboratory of electronics, Massachusetts Institute of Technology},
title = {{A unified theory of information}},
volume = {311},
year = {1956}
}

@book{definetti2008,
author = {de Finetti, Bruno},
editor = {Mura, Alberto},
file = {:Users/jarotter/Documents/estadistica/bayesiana/filosofia/definetti-philosophical-lectures.pdf:pdf},
publisher = {Springer Science + Business Media},
title = {{Philosophical Lectures on Probability}},
year = {2008}
}

@article{ep,
abstract = {A common approach for Bayesian computation with big data is to partition the data into smaller pieces, perform local inference for each piece separately, and finally combine the results to obtain an approximation to the global posterior. Looking at this from the bottom up, one can perform separate analyses on individual sources of data and then combine these in a larger Bayesian model. In either case, the idea of distributed modeling and inference has both conceptual and computational appeal, but from the Bayesian perspective there is no general way of handling the prior distribution: if the prior is included in each separate inference, it will be multiply-counted when the inferences are combined; but if the prior is itself divided into pieces, it may not provide enough regularization for each separate computation, thus eliminating one of the key advantages of Bayesian methods. To resolve this dilemma, we propose expectation propagation (EP) as a general prototype for distributed Bayesian inference. The central idea is to factor the likelihood according to the data partitions, and to iteratively combine each factor with an approximate model of the prior and all other parts of the data, thus producing an overall approximation to the global posterior at convergence. In this paper, we give an introduction to EP and an overview of some recent developments of the method, with particular emphasis on its use in combining inferences from partitioned data. In addition to distributed modeling of large datasets, our unified treatment also includes hierarchical modeling of data with a naturally partitioned structure. The paper describes a general algorithmic framework, rather than a specific algorithm, and presents an example implementation for it.},
archivePrefix = {arXiv},
arxivId = {1412.4869},
author = {Vehtari, Aki and Gelman, Andrew and Sivula, Tuomas and Jyl{\"{a}}nki, Pasi and Tran, Dustin and Sahai, Swupnil and Blomstedt, Paul and Cunningham, John P. and Schiminovich, David and Robert, Christian},
eprint = {1412.4869},
file = {:Users/jarotter/Documents/estadistica/bayesiana/c{\'{o}}mputo/expectation-propagation.pdf:pdf},
title = {{Expectation propagation as a way of life: A framework for Bayesian inference on partitioned data}},
url = {http://arxiv.org/abs/1412.4869},
year = {2014}
}

@article{jeffreys1946,
abstract = {It is shown that a certain differential form depending on the values of the parameters in a law of chance is invariant for all transformations of the parameters when the law is differentiable with regard to all parameters. For laws containing a location and a scale parameter a form with a somewhat restricted type of invariance is found even when the law is not everywhere differentiable with regard to the parameters. This form has the properties required to give a general rule for stating the prior probability in a large class of estimation problems.},
author = {Jeffreys, Harold},
doi = {10.1098/rspa.1946.0056},
file = {:Users/jarotter/Documents/ITAM/tesis/docs/vi/kl/jeffreys1946.pdf:pdf},
issn = {0950-1207},
journal = {Proceedings of the Royal Society of London. Series A, Mathematical and physical sciences},
number = {1007},
pages = {453--61},
pmid = {20998741},
title = {{An invariant form for the prior probability in estimation problems.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20998741},
volume = {186},
year = {1946}
}

@book{amari2016,
address = {Tokyo},
author = {Amari, Shun-ichi},
doi = {10.1007/978-3-319-47058-0_1},
file = {:Users/jarotter/Documents/mathematics/information-geometry/(Applied Mathematical Sciences 194) Shun-ichi Amari (auth.)-Information Geometry and Its Applications-Springer Japan (2016).pdf:pdf},
isbn = {9784431559771},
publisher = {Springer},
title = {{Information Geometry and Its Applications: An Overview}},
year = {2016}
}

@book{kullback1959,
  address = {New York},
  author = {Kullback, Solomon},
  booktitle = {Information Theory and Statistics},
  publisher = {Wiley},
  title = {Information Theory and Statistics},
  year = 1959
}


