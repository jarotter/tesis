\documentclass[main.tex]{subfiles}
\begin{document}

\chapter{Inferencia variacional}
%La inferencia variacional busca aproximar una medida de probabilidad $p$ con la $q\in\mathcal{Q}$ que más se le parezca en cierto sentido. Formalmente, se elige la solución a la ecuación \eqref{eqn:vi} que reescribimos aquí
%
%\begin{equation*}
%	q^* = \argmin_{q \in \mathcal{Q}} D_{KL}(q\mmidp)
%\end{equation*}
%
%Para estudiar con detenimiento la función objetivo de la inferencia variacional, la construimos a partir de teoría de decisión con la doble intención de profundizar en la inferencia variacional y en el marco bayesiano. 

\section{Teoría de decisión}
\begin{definition}
	Un \textit{problema de decisión} es una tupla $(\Omega, \mathcal{C}, \mathcal{D}, \preceq)$ donde
	\begin{itemize}
		\item $\Omega$ es un $\sigma$-álgebra de eventos relevantes $\omega$
		\item $\mathcal{C}$ es un conjunto de consecuencias $c$
		\item $\mathcal{D}$ es un conjunto de decisiones y 
		\item $\prec$ es una relación binaria en $D$.
	\end{itemize}
\end{definition}
	
Esta definición intenta formalizar la experiencia de un individuo o grupo (a quien llamaremos tomadora de decisiones) que debe elegir una opción de $\mathcal{D}$ en contexto de incertidumbre. Ella tiene control sobre la decisión que toma, pero una vez elegida $d$ puede ocurrir cualquiera de los eventos $\omega$, y la combinación trae como consecuencia a $c$. La teoría bayesiana postula una serie de axiomas para resolver problemas de decisión sin caer en errores sistemáticos. Para una construcción detallada el lector puede referirse a \cite{bernardo}, pero las principales consecuencias que derivan de ellos son
\begin{enumerate}[label=\roman*]
	\item toda incertidumbre sobre $\Omega$ puede extraerse de $\prec$ y cuantificarse en una medida de probabilidad $p(\omega)$
	\item toda preferencia debe cuantificarse en una \textit{función de utilidad} \\  $u: \mathcal{D}\times\Omega \to \mathbb{R}$  que captura la utilidad de haber tomado la decisión $d$ dado que ocurrió el evento   $\omega$ y
	\item la solución al problema de decisión consistente con los axiomas de coherencia es elegir la decisión que maximice la utilidad esperada.
	\item la manera en que la tomadora de decisiones debe actualizar sus creencias sobre $\omega$, dado que sucedió un evento $\delta$, es usando el teorema de Bayes \eqref{eqn:bayes-thm}
		\begin{equation*}
		p(\omega\mid\delta) = \frac{p(\delta\mid\omega)p(\omega)}{p(\delta)}
		\end{equation*}

\end{enumerate}

\begin{definition}
	La \textit{solución bayesiana} a un problema de decisión es 
	\begin{equation}
	d^* = \argmax_{d \in\mathcal{D}} \ \mathbb{E}_{\omega\sim p}\left[u(d, \omega)\right]
	\end{equation}
\end{definition}

La notación anterior es un poco abstracta, pero en el caso de datos $x$ generados por un modelo de probabilidad $p(x \mid \theta)$, si inicialmente la tomadora de decisiones cuantifica su incertidumbre sobre $\theta$ con una distribución $p(\theta)$, la manera de actualizar se escribe en la familiar forma

\begin{equation*}
	p(\theta | x ) 	\propto p(x|\theta)p(\theta).
\end{equation*}

En \cite{bernardo} se muestra que los problemas de estimación puntual, estimación por regiones y contraste de hipótesis pueden plantearse como problemas de decisión, tanto en contextos de inferencia pura como de pronóstico. Esta absoluta generalidad es importante de resaltar, pues todo problema estadístico puede resolverse con el mismo camino: basta dar iniciales, elegir una utilidad y maximizar.

Ahora consideraremos un problema de decisión particular que, aunque suene un poco artificial en primera instancia, es de hecho la definición operativa\footnote{Es decir, que pueda utilizarse en el mundo real y operar con números} que Bruno De Finetti usa para probabilidad en \cite{definetti2008}.  Supongamos que interesa cuantificar en una medida de probabilidad la incertidumbre que una tomadora de decisiones tiene acerca de un evento en el que debe ocurrir alguna posibilidad  $\omega \in \Omega$. Ella debe reportar una distribución de probabilidad para las $\omega$, pero nada la obliga a revelar sus verdaderas creencias. Si una vez ocurrido el evento de interés se le recompensará con una cantidad $u(\omega,p(\omega))$ que depende del evento que haya ocurrido y de las probabilidades que había expresado; ¿podrá la función $u$  asegurar que ella reportará sus verdaderas creencias?  Este problema se lo planteó Glenn Brier en 1959 para encontrar una manera de evaluar las predicciones meteorológicas, y la solución que le dio sigue recibiendo su nombre. 

\begin{definition}
	Consideremos un problema de decisión donde el conjunto de decisiones $\mathcal{Q}$ es el de distribuciones de probabilidad sobre ciertos eventos $\Omega$. A la utilidad $u: \mathcal{Q}\times\Omega \to \mathbb{R}$ se le llama \textit{función score}.
\end{definition}

Si la tomadora de decisiones siguiera los axiomas de coherencia, su respuesta sería reportar la distribución que maximice la utilidad esperada. Sin embargo, ella tiene una verdadera distribución de creencias, que denotaremos $p$. 

\begin{definition}
	Una función score $u$ es \textit{propia} si
	\begin{equation*}
		\sup_{q \in \mathcal{Q}} \mathbb{E}_{\omega\sim p}\left[u(q,\omega)\right] = \mathbb{E}_{\omega\sim p}\left[u(p,\omega)\right]
	\end{equation*}
\end{definition}

Es decir, si la tomadora de decisiones maximiza su utilidad esperada reportando sus verdaderas creeencias. Brier probó que la pérdida cuadrática (o de Brier) es una función score propia.

Otra característica que puede incorporarse a la función score del problema, y que Bernardo argumenta es lo que debería hacerse en el conocimiento científico, es sólo evaluar la respuesta en términos de la probabilidad que asigna al evento que sí ocurrió. Esto permite ignorar lo poco acertada que pudo haber sido la tomadora de decisiones en algo que no ocurrió y por tanto no hay forma \enquote{honesta} o \enquote{justa} de evaluar. Como ejemplo para concretar, si se está modelando la probabilidad de que uno de tres eventos (digamos $A, B, C$) suceda y al final sucede $A$, se quiere recompensar a la tomadora de decisiones utilizando solamente la probabilidad que asignó a $A$, sin importar cuánto haya asignado a $B$ y $C$. 

\begin{definition}
	Una función score $u$ es \textit{local} si para cada $q \in \mathcal{Q}$ existen funciones $\{u_\omega: \omega\in\Omega\}$ tales que
	\begin{equation*}
		u(q, \omega) = u_\omega(q)
	\end{equation*}
\end{definition}

El siguiente teorema se prueba en \cite{bernardo} y caracteriza, bajo ciertas condiciones de regularidad, a las funciones score propias.

\begin{prop}
	Si $u:\mathcal{Q}\times\Omega \to \mathbb{R}$ es una función score propia, local y continuamente diferenciable tal que $\mathbb{E}_{\omega \sim p}\left[u(q,\omega)\right] < \infty$ para cada $q \in \mathcal{Q}$, entonces u debe ser de la forma
	\begin{equation*}
		u(q, \omega) = a\log q(\omega)+b_\omega
	\end{equation*}
\end{prop} 

\begin{definition}
A una función score que satisfaga las hipótesis de la proposición 2.1 se le llama \textit{score logarítmica}.	
\end{definition}

Ahora bien, la tomadora de decisiones puede encontrarse en una situación en la que, por dificultad computacional o cualquier otra razón no pueda reportar $p$, sino solamente una aproximación $q$. En este caso, la diferencia en utilidad esperada de la tomadora de decisiones es 

\begin{align*}
	\Delta &= \mathbb{E}_{\omega \sim p}\left[u(p, \omega)\right] - \mathbb{E}_{\omega\sim p}\left[u(q, \omega)\right]  \\
	&= \mathbb{E}_{\omega \sim p}\left[u(p, \omega) - u(q, \omega)\right] \\
	&= \mathbb{E}_{\omega \sim p}\left[(a\log p(\omega) - b_\omega) - (a\log q(\omega) - b_\omega) \right] \\
	&= a\mathbb{E}_{\omega \sim p}\left[\log\frac{p(\omega)}{q(\omega)}\right]
\end{align*}

\begin{definition}
	Cuando $a=1$, la expresión de arriba se llama \textit{divergencia de Kullback-Leibler} de $p$ a $q$. Es decir, 
	\begin{equation*}
	\kl(p \mmid q) = \mathbb{E}_{\omega \sim p}\left[\log\frac{p(\omega)}{q(\omega)}\right]	
	\end{equation*}
Si $p$ y $q$ son miembros de la misma familia paramétrica, digamos $p(x)=f(x; \theta_0)$ y $q(x)=f(x; \theta_1)$, también se usa la notación $\kl(\theta_0\mmid\theta_1)$.
\end{definition}

\section{La divergencia de Kullback-Leibler}
El término \textit{divergencia} es importante de resaltar; pues aunque la definición constructiva de $\kl$ muestra que efectivamente mide una diferencia, no es una métrica en el sentido estricto, pues no es simétrica ni satisface la desigualdad del triángulo. La simetría puede obligarse de la manera usual, pero la función que resulta tampoco es una métrica.

\begin{definition}
La \textit{divergencia simétrica de Kullback-Leibler} es la función $\skl$ definida por
\begin{equation*}
2\skl(p, q) = \kl(p\mmid q) + \kl(q \mmid p)	
\end{equation*}
\end{definition}

A continuación se prueban algunas propiedades de la divergencia de Kullback-Leibler.

\begin{theorem}[Propiedades de $\kl$ -- caso general] \ \\
Consideremos una familia $\mathcal{F}$ de distribuciones de probabilidad para una variable aleatoria $X$ con densidades generalizadas $\{p\}$. Entonces,
\begin{enumerate}[label=\roman*.]

\item $\kl(p \mmid q) \geq 0$ para todas $p, q$ con igualdad si y sólo si $q \ll p$ y $p=q$ casi en donde quiera (relativo a P).
\item $\kl$ es convexa en ambos argumentos
\item Para toda transformación invertible $X=g^{-1}(Y)$,
		\begin{equation*}
		\kl\left(f_Y(y;\theta_0), f_Y(y;\theta_1)\right) =
		\kl\left(f_X(x;\theta_0), f_X(x;\theta_1)\right) 
		\end{equation*}
\end{enumerate}
\end{theorem}
\begin{proof} \ \\
Nótese primero que por la desigualdad de Jensen,
\begin{equation*}
-\kl(p\mmid q) 
	= \mathbb{E}_{x\sim p}\left[\log\frac{q(x)}{p(x)}\right]
	\leq\log\mathbb{E}_{x\sim p}\left[\frac{q(x)}{p(x)}\right]
\end{equation*}

Usando la convención $\log\frac{0}{0}=0$, el término de la derecha es 0 si y sólo si $p(x)=q(x)$ casi en donde quiera (relativo a $P$) y cuando $p(x)=0$ debe darse que $q(x)=0$. \\

La prueba de convexidad es estándar. Definamos
\begin{align*}
	P_\lambda = (1-\lambda)P_0	
\end{align*}


Para probar $(iii)$, basta observar que por ser una reparametrización, se cumple por definición que $f_\varphi(x, \varphi(\theta))=f(x, \theta)$ para todas $\theta, x$. \\


\begin{theorem}[Propiedades de $\kl$ -- caso paramétrico] \ \\
Consideremos una familia paramétrica $\mathcal{F} = \{f(\ \cdot \ ;\theta): \theta \in \Theta \}$ de distribuciones de probabilidad para una variable aleatoria $X$. Entonces,
\begin{enumerate}[label=\roman*.]
	\item para toda reparametrización $\varphi$,
		\begin{equation*}
		\kl\left(\varphi(\theta_0)\mmid\varphi(\theta_1)\right) = 
			\kl\left(\theta_0\mmid\theta_1\right)
		\end{equation*}
		
	\item $\kl(\theta_0\mmid \theta_1)$ es de orden dos en $\|\theta_0-\theta_1\|$.
\end{enumerate} 
\end{theorem}
\begin{proof}
Para $(iv)$, nótese que por el teorema de cambio de variable
\begin{equation*}
\frac{f_Y(y;\theta_0)}{f_Y(y;\theta_1)} = 
\frac{f_X\left(g^{-1}(y); \theta_0\right)\mid\frac{dg}{dy}\mid}
{f_X\left(g^{-1}(y); \theta_1\right)\mid\frac{dg}{dy}\mid} = 
\frac{f_X(x;\theta_0)}{f_X(x;\theta_1)}
\end{equation*}
\end{proof}

y sustituyendo en la definición 2.7 se obtiene el resultado. \\


Finalmente, por 
\end{proof}




\end{document}