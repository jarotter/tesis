\documentclass[main.tex]{subfiles}
\begin{document}

\chapter{Introducción}
La estadística bayesiana interpreta la probabilidad no como un límite de frecuencias relativas en repeticiones independientes de un experimento, sino como la cuantificación de la incertidumbre personal. Así, es posible hablar de situaciones como \textquote{la probabilidad de que los demócratas ganen la elección en 2020} aunque sea imposible repetirlo. En el contexto de un modelo estadístico en el que un fenómeno $X$ tiene una medida de probabilidad parametrizada por $\theta \in \Theta$, esta diferencia epistemológica decanta en la asignación de una medida de probabilidad $p(\theta)$. La inferencia bayesiana se interpreta entonces como actualizar las creencias acerca de $\theta$ usando el teorema de Bayes

\begin{equation}
	p(\theta | x) = \frac{p(x|\theta)p(\theta)}{p(x)}
	\label{eqn:bayes-thm}	
\end{equation}

Al término del lado izquierdo se le llama \textit{probabilidad posterior}, y refleja el cambio en nuestra incertidumbre tras observar los datos $x$. Como extensión, el marco de referencia bayesiano permite hacer predicciones y revisión de modelos de manera sencilla, pues basta simular de la \textit{posterior predictiva} 

\begin{equation*}
	p(x^*) = \int_\Theta p(x^*|\theta)p(\theta | x) d\theta	
\end{equation*}

La asignación de una distribución de probabilidad completa a cada parámetro asegura que la incertidumbre pueda cuantificarse de una manera efectiva, sistemática y capaz de incorporar los datos observados y estructuras de dependencia entre todas las variables.

Sin embargo, el denominador en \eqref{eqn:bayes-thm} es un cuello de botella computacional, pues es una integral complicada en dimensiones usualmente altas. En la práctica se utilizan algoritmos para obtener muestras de $p(\theta |x)$ sin conocer su forma explícita. Los \textit{métodos de Monte Carlo con cadenas de Markov} (MCMC por sus siglas en inglés y a partir de ahora) construyen una cadena de Markov ergódica cuya distribución estacionaria es $p(\theta | x)$, de manera que desde cualquier punto inicial pueda obtenerse una cadena que a la larga dé muestras de la posterior \cite{robert-book}. Estos algoritmos facilitaron el uso de procedimientos bayesianos, pero en modelos complicados, asegurar la convergencia es difícil y no escalan al tamaño masivo de los conjuntos de datos modernos.

Para mejorar la convergencia de MCMC, existen algoritmos que exploran $\Theta$ de manera más eficiente usando ideas de mecánica estadística \cite{betancourt-hmc}, pero siguen sin ser suficientemente rápidos para usarse en grandes volúmenes. Trabajo reciente de Broderick y Campbell \cite{coresets, coresets-greedy} propone métodos para construir \textit{coresets}, submuestras ponderadas que aproximan la verosimilitud completa de los datos, y efectivamente reducen el tamaño de muestra. De manera simular, \textit{expectation propagation} \cite{ep} permite paralelizar la inferencia con subconjuntos de datos. Como trabajan sobre el uso de datos y no sobre un algoritmo \textit{per se}, estas ideas son perfectamente compatible con MCMC y con la clase de algoritmos que este trabajo estudiará: los variacionales.

Los algoritmos frecuentistas se benefician del descenso en gradiente estocástico, que utiliza muestras pequeñas para estimar el gradiente de la función de pérdida, y pueden así utilizarse en contextos masivos \cite{goodfellow}. Para usar esta ventaja en la formulación bayesiana, la inferencia debe traducirse de un problema de integración a un problema de optimización. Como veremos con detenimiento en el siguiente capítulo, una formulación natural es aproximar la posterior $p$ con la distribución $q^*$ que minimice la divergencia de Kullback-Leibler de $q$ a $p$ en un conjunto $\mathcal{Q}$.  


\begin{equation}
	q^* = \argmin_{q \in \mathcal{Q}} D_{KL}(q || p)
	\label{eqn:vi}	
\end{equation}

A los métodos que resuelven este problema se les llama \textit{variacionales}. A diferencia de MCMC, los métodos variacionales no son exactos ni siquiera asintóticamente, pero son muy atractivos por su sencillez computacional. Por supuesto,  la calidad de la solución depende del espacio $\mathcal{Q}$, que tiene que ser suficientemente rico para aproximar fielmente a $p$ pero suficientemente estructurado para que el algoritmo converja y su implementación sea robusta. En este texto se presenta un algoritmo variacional no paramétrico propuesto por Liu y Wang \cite{svgd}, que elige como $\mathcal{Q}$ un espacio de Hilbert con núcleo reproductor (EHNR a partir de ahora) para balancear entre flexibilidad y facilidad de cómputo. 

%
{\color{red} ESTRUCTURA DEL DOCUMENTO}
\end{document}
